{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Honner/CMWTAT_Digital_Edition/blob/master/docs/sphinx/source/examples/simplified-retrieval-with-colpali-vlm_Vespa-cloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzoiJTAoZobv"
      },
      "source": [
        "<picture>\n",
        "  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-green-RGB.svg\">\n",
        "  <source media=\"(prefers-color-scheme: light)\" srcset=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\">\n",
        "  <img alt=\"#Vespa\" width=\"200\" src=\"https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg\" style=\"margin-bottom: 25px;\">\n",
        "</picture>\n",
        "\n",
        "# Scaling ColPALI (VLM) Retrieval\n",
        "\n",
        "This notebook demonstrates how to represent [ColPali](https://huggingface.co/vidore/colpali) in Vespa\n",
        "and to scale to large collections. Also see the blog post: [Scaling ColPali to billions of PDFs with Vespa](https://blog.vespa.ai/scaling-colpali-to-billions/)\n",
        "\n",
        "Consider following the [ColQWen2](https://vespa-engine.github.io/pyvespa/examples/pdf-retrieval-with-ColQwen2-vlm_Vespa-cloud.html) notebook instead as it\n",
        "use a better model with improved performance (Both accuracy and speed).\n",
        "\n",
        "ColPali is a powerful visual language model that can generate embeddings for images (screenshots of PDF pages) and text queries.\n",
        "\n",
        "In this notebook, we will use ColPali to generate embeddings for images of PDF _pages_ and store the embeddings in Vespa.\n",
        "We will also store the base64 encoded image of the PDF page and meta data like title and url.\n",
        "\n",
        "We demonstrate how to retrieve relevant pages for a query using the embeddings generated by ColPali.\n",
        "\n",
        "The TLDR of this notebook:\n",
        "\n",
        "- Generate an image per PDF page using [pdf2image](https://pypi.org/project/pdf2image/)\n",
        "and also extract the text using [pypdf](https://pypdf.readthedocs.io/en/stable/user/extract-text.html).\n",
        "- For each page image, use ColPali to obtain the visual multi-vector embeddings\n",
        "\n",
        "Then we store visual embeddings in Vespa as a `int8` tensor, where we use a binary compression technique\n",
        "to reduce the storage footprint by 32x compared to float representations. See [Scaling ColPali to billions of PDFs with Vespa](https://blog.vespa.ai/scaling-colpali-to-billions/)\n",
        "for details on binarization and using hamming distance for retrieval.\n",
        "\n",
        "During retrieval time, we use the same ColPali model to generate embeddings for the query and then use Vespa's `nearestNeighbor` query to retrieve the most similar documents\n",
        "per query vector token, using binary representation with hamming distance. Then we re-rank the results in two phases:\n",
        "\n",
        "- In the 0-phase we use hamming distance to retrieve the k closest pages per query token vector representation, this is expressed by using multiple nearestNeighbor query operators in Vespa.\n",
        "- The nearestNeighbor operators exposes pages to the first-phase ranking function, which uses an approximate MaxSim using inverted hamming distance insted of cosine similarity. This is done to reduce the number of pages that are re-ranked in the second phase.\n",
        "- In the second phase, we perform the full MaxSim operation, using float representations of the embeddings to re-rank the top-k pages from the first phase.\n",
        "\n",
        "This allows us to scale ColPali to very large collections of PDF pages, while still providing accurate and fast retrieval.\n",
        "\n",
        "Let us get started.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vespa-engine/pyvespa/blob/master/docs/sphinx/source/examples/simplified-retrieval-with-colpali-vlm_Vespa-cloud.ipynb)\n",
        "\n",
        "\n",
        "Install dependencies:\n",
        "\n",
        "Note that the python pdf2image package requires poppler-utils, see other installation options [here](https://pdf2image.readthedocs.io/en/latest/installation.html#installing-poppler)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "El9yEEwjMr81",
        "outputId": "0c3ef5ff-8620-4656-e0ca-dfc4e0eb5d91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,929 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,520 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,111 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,575 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,208 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,270 kB]\n",
            "Fetched 17.0 MB in 4s (4,757 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.9 [186 kB]\n",
            "Fetched 186 kB in 0s (442 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.9_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.9) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.9) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update && sudo apt-get install poppler-utils -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhhFO1dyMr82"
      },
      "source": [
        "Now install the required python packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VIly_Pymmbyl",
        "outputId": "7e579034-280e-463f-cc9b-8486a895b4d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.51.3\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Collecting vidore_benchmark==4.0.0\n",
            "  Downloading vidore_benchmark-4.0.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pypdf==5.0.1\n",
            "  Downloading pypdf-5.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting pyvespa\n",
            "  Downloading pyvespa-0.59.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting vespacli\n",
            "  Downloading vespacli-8.562.17-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.34.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (4.67.1)\n",
            "Collecting colpali-engine<0.4.0,>=0.3.0 (from vidore_benchmark==4.0.0)\n",
            "  Downloading colpali_engine-0.3.12-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting datasets<3.0.0,>=2.15.0 (from vidore_benchmark==4.0.0)\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: einops<1.0.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from vidore_benchmark==4.0.0) (0.8.1)\n",
            "Collecting gputil<2.0.0,>=1.4.0 (from vidore_benchmark==4.0.0)\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting loguru<1.0.0,>=0.7.0 (from vidore_benchmark==4.0.0)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting mteb<2.0.0,>=1.12.47 (from vidore_benchmark==4.0.0)\n",
            "  Downloading mteb-1.38.39-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft<0.13.0,>=0.11.1 (from vidore_benchmark==4.0.0)\n",
            "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pillow<11.0.0,>=9.2.0 (from vidore_benchmark==4.0.0)\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from vidore_benchmark==4.0.0)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting sentence-transformers<4.0.0,>=3.0.1 (from vidore_benchmark==4.0.0)\n",
            "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sentencepiece<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from vidore_benchmark==4.0.0) (0.2.0)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from vidore_benchmark==4.0.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.12.3 in /usr/local/lib/python3.11/dist-packages (from vidore_benchmark==4.0.0) (0.16.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: requests_toolbelt in /usr/local/lib/python3.11/dist-packages (from pyvespa) (1.0.0)\n",
            "Collecting docker (from pyvespa)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyvespa) (3.1.6)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from pyvespa) (43.0.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from pyvespa) (3.12.15)\n",
            "Requirement already satisfied: httpx[http2] in /usr/local/lib/python3.11/dist-packages (from pyvespa) (0.28.1)\n",
            "Requirement already satisfied: tenacity>=8.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvespa) (8.5.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from pyvespa) (4.14.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from pyvespa) (2.9.0.post0)\n",
            "Requirement already satisfied: fastcore>=1.7.8 in /usr/local/lib/python3.11/dist-packages (from pyvespa) (1.7.29)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from pyvespa) (5.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.8.3)\n",
            "INFO: pip is looking at multiple versions of colpali-engine to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting colpali-engine<0.4.0,>=0.3.0 (from vidore_benchmark==4.0.0)\n",
            "  Downloading colpali_engine-0.3.11-py3-none-any.whl.metadata (34 kB)\n",
            "  Downloading colpali_engine-0.3.10-py3-none-any.whl.metadata (33 kB)\n",
            "  Downloading colpali_engine-0.3.9-py3-none-any.whl.metadata (31 kB)\n",
            "  Downloading colpali_engine-0.3.8-py3-none-any.whl.metadata (27 kB)\n",
            "  Downloading colpali_engine-0.3.7-py3-none-any.whl.metadata (26 kB)\n",
            "  Downloading colpali_engine-0.3.6-py3-none-any.whl.metadata (25 kB)\n",
            "  Downloading colpali_engine-0.3.5-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting peft<0.13.0,>=0.11.1 (from vidore_benchmark==4.0.0)\n",
            "  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
            "INFO: pip is still looking at multiple versions of colpali-engine to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting colpali-engine<0.4.0,>=0.3.0 (from vidore_benchmark==4.0.0)\n",
            "  Downloading colpali_engine-0.3.4-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading colpali_engine-0.3.3-py3-none-any.whl.metadata (18 kB)\n",
            "  Downloading colpali_engine-0.3.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.15.0->vidore_benchmark==4.0.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.15.0->vidore_benchmark==4.0.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.15.0->vidore_benchmark==4.0.0) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.15.0->vidore_benchmark==4.0.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.15.0->vidore_benchmark==4.0.0) (0.70.16)\n",
            "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<3.0.0,>=2.15.0->vidore_benchmark==4.0.0)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (1.1.7)\n",
            "Requirement already satisfied: scikit_learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from mteb<2.0.0,>=1.12.47->vidore_benchmark==4.0.0) (1.6.1)\n",
            "Requirement already satisfied: scipy>=0.0.0 in /usr/local/lib/python3.11/dist-packages (from mteb<2.0.0,>=1.12.47->vidore_benchmark==4.0.0) (1.16.1)\n",
            "Requirement already satisfied: rich>=0.0.0 in /usr/local/lib/python3.11/dist-packages (from mteb<2.0.0,>=1.12.47->vidore_benchmark==4.0.0) (13.9.4)\n",
            "Collecting pytrec-eval-terrier>=0.5.6 (from mteb<2.0.0,>=1.12.47->vidore_benchmark==4.0.0)\n",
            "  Downloading pytrec_eval_terrier-0.5.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (984 bytes)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from mteb<2.0.0,>=1.12.47->vidore_benchmark==4.0.0) (2.11.7)\n",
            "Collecting eval_type_backport>=0.0.0 (from mteb<2.0.0,>=1.12.47->vidore_benchmark==4.0.0)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: polars>=0.20.22 in /usr/local/lib/python3.11/dist-packages (from mteb<2.0.0,>=1.12.47->vidore_benchmark==4.0.0) (1.25.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0) (3.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.0.0->vidore_benchmark==4.0.0) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.12.3->vidore_benchmark==4.0.0) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.12.3->vidore_benchmark==4.0.0) (1.5.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->pyvespa) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->pyvespa) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->pyvespa) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->pyvespa) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->pyvespa) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->pyvespa) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->pyvespa) (1.20.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->pyvespa) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx[http2]->pyvespa) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx[http2]->pyvespa) (1.0.9)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]->pyvespa) (4.2.0)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx[http2]->pyvespa) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyvespa) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->pyvespa) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->pyvespa) (2.22)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]->pyvespa) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]->pyvespa) (4.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->mteb<2.0.0,>=1.12.47->vidore_benchmark==4.0.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->mteb<2.0.0,>=1.12.47->vidore_benchmark==4.0.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->mteb<2.0.0,>=1.12.47->vidore_benchmark==4.0.0) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=0.0.0->mteb<2.0.0,>=1.12.47->vidore_benchmark==4.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=0.0.0->mteb<2.0.0,>=1.12.47->vidore_benchmark==4.0.0) (2.19.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>=1.0.2->mteb<2.0.0,>=1.12.47->vidore_benchmark==4.0.0) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>=1.0.2->mteb<2.0.0,>=1.12.47->vidore_benchmark==4.0.0) (3.6.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx[http2]->pyvespa) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<3.0.0,>=2.15.0->vidore_benchmark==4.0.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<3.0.0,>=2.15.0->vidore_benchmark==4.0.0) (2025.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=0.0.0->mteb<2.0.0,>=1.12.47->vidore_benchmark==4.0.0) (0.1.2)\n",
            "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vidore_benchmark-4.0.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.0.1-py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pyvespa-0.59.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vespacli-8.562.17-py3-none-any.whl (47.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colpali_engine-0.3.2-py3-none-any.whl (37 kB)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mteb-1.38.39-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.9/275.9 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytrec_eval_terrier-0.5.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.0/288.0 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=98ead92310cb85118f8db4ebe1ea1b807c3008269f4f7b5141cb458660fc88b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n",
            "Successfully built gputil\n",
            "Installing collected packages: vespacli, gputil, pytrec-eval-terrier, python-dotenv, pypdf, pillow, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, loguru, fsspec, eval_type_backport, pdf2image, nvidia-cusparse-cu12, nvidia-cudnn-cu12, docker, nvidia-cusolver-cu12, transformers, pyvespa, datasets, sentence-transformers, peft, mteb, colpali-engine, vidore_benchmark\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.55.0\n",
            "    Uninstalling transformers-4.55.0:\n",
            "      Successfully uninstalled transformers-4.55.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 5.0.0\n",
            "    Uninstalling sentence-transformers-5.0.0:\n",
            "      Successfully uninstalled sentence-transformers-5.0.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.17.0\n",
            "    Uninstalling peft-0.17.0:\n",
            "      Successfully uninstalled peft-0.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colpali-engine-0.3.2 datasets-2.21.0 docker-7.1.0 eval_type_backport-0.2.2 fsspec-2024.6.1 gputil-1.4.0 loguru-0.7.3 mteb-1.38.39 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 pdf2image-1.17.0 peft-0.11.1 pillow-10.4.0 pypdf-5.0.1 python-dotenv-1.1.1 pytrec-eval-terrier-0.5.7 pyvespa-0.59.0 sentence-transformers-3.4.1 transformers-4.51.3 vespacli-8.562.17 vidore_benchmark-4.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "numpy"
                ]
              },
              "id": "ef4cd24879a84db9b5b76c3f2fa35bad"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip3 install transformers==4.51.3 accelerate vidore_benchmark==4.0.0 pdf2image pypdf==5.0.1 pyvespa vespacli requests numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qKFOvdo5nCVl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from io import BytesIO\n",
        "\n",
        "from transformers import ColPaliForRetrieval, ColPaliProcessor\n",
        "from vidore_benchmark.utils.image_utils import scale_image, get_base64_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGfNhRP4RKBJ"
      },
      "source": [
        "### Load the model\n",
        "\n",
        "This requires that the HF_TOKEN environment variable is set as the underlaying PaliGemma model is hosted on Hugging Face\n",
        "and has a [restricive licence](https://ai.google.dev/gemma/terms) that requires authentication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h72zWP2GMr83"
      },
      "source": [
        "Choose the right device to run the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "--JScDKeMr83"
      },
      "outputs": [],
      "source": [
        "# Load model (bfloat16 support is limited; fallback to float32 if needed)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if torch.backends.mps.is_available():\n",
        "    device = \"mps\"  # For Apple Silicon devices\n",
        "dtype = torch.bfloat16 if torch.cuda.is_available() else torch.float32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxZ9kJiGMr84"
      },
      "source": [
        "Load the model and the processor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284,
          "referenced_widgets": [
            "9b5672a16be04e3981882b338ee52618",
            "d67bb152de9c40be99fbf9036415a007",
            "2545fd7c8e75489cb84a8e55d04b0a9e",
            "3bd710c8728146df8d2108f9906e6e66",
            "aa6badb696b345fe9241052af409647c",
            "964bea24e4a947699e98b4e347305694",
            "7e625e90e4ac495d895202744bf36e2f",
            "3de350f3eb3b49fca11f14d11fa8416e",
            "986d2d53b95f4490b04db050d17763c2",
            "02956fb81b0a489e9e1d0cf00af2c739",
            "4ee99609ec534a059bcff4f788166849",
            "1490c3af015448088277755693125d35",
            "a2b7592676fe4b07a7d3a8cd294e7f75",
            "a220fdcb2cf14cde8ea6ae6baf154267",
            "c52189f0f186493da9036acedd9cf8b7",
            "2b64057c89144bbabb001fba75402bf3",
            "604a2759912a42f3921569626cf04d60",
            "a2369645d7544597b5e481beb007adf0",
            "4301536cda4541808a8dfa7d50340b10",
            "c1edb8d32148467dbd4d2b971b35d602",
            "5c276cb31cc24e19ae864bd3284369cb",
            "5690c1579912452fb0106ac3038862ce",
            "9cbb6e9203a14db5b82f3967370aec64",
            "78621a41f4b341c39cf1dcadfc7284fd",
            "5d8e9a315d2643c6b69d4f4c99372276",
            "8b271605a2f94b8daa100d9e41baa6b9",
            "bae55b3298f44a4fb9978a7983dce764",
            "482f308812374853a3f73e8343359101",
            "e52a23a75dfd4c4e8ec257dfbd6404af",
            "1e50ce4a951949efbd49636fc26941bc",
            "bddb2de8291f43b9a0bfb47f9d0eacad",
            "c1102a3de22d4403a65681138165a151",
            "032cbae8047649f7bd22daad505a0c17",
            "374fd86b4b1a4a87a61e896964ddf8a6",
            "ecd30cda8f3c45bd91829b5fee468b6e",
            "40fdf79571ac4b638d252c9d9f24b59b",
            "8b1c0fdbd3a742b5b4dd213b348ba6cb",
            "0e1f204dd80840d981c59b1ae5cd2b0c",
            "baf29665b4f04822aad9b69ede4d307b",
            "34dee48cdaa246c1a44453d43634c657",
            "19dd3dcae1244ca8b461027b31a78add",
            "e9609ec9a25c49d2b74ecc4d75e0ea07",
            "d887f859e942484b906ba9162b831ef8",
            "d1d5d2ffa6844956a868867023dfc3f3",
            "c95c26d58e984123b493a91a78530493",
            "96ef6b50c5d443a69472508fe2a8fec8",
            "3964bcff08f7480ab94bb4e232fbff03",
            "595692f07b2541ce869f15b53efedfb5",
            "2f4be02421f74a64a805b34319550ca1",
            "3181b6eae242418d8ad240fe71dae9f8",
            "29639bfd4b6648df9d20dc33430d0d08",
            "c262e8d2c5474b9a87cbb58113432fe9",
            "f72f7c7bd7614c79a09ed3e0740098a2",
            "6801b8d612ac492f9f5588bc6e7461cf",
            "849e9a2837bd42a18289d6c5abf483d4"
          ]
        },
        "id": "bpvPYA1HnMDp",
        "outputId": "b371e03b-bc94-4311-b759-f01e2184c666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b5672a16be04e3981882b338ee52618"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1490c3af015448088277755693125d35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cbb6e9203a14db5b82f3967370aec64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "374fd86b4b1a4a87a61e896964ddf8a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/862M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c95c26d58e984123b493a91a78530493"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = \"vidore/colpali-v1.2-hf\"\n",
        "model = ColPaliForRetrieval.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=dtype,\n",
        "    device_map=device,  # \"cpu\", \"cuda\", or \"mps\" for Apple Silicon\n",
        ").eval()\n",
        "\n",
        "processor = ColPaliProcessor.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUqnrKWLak3O"
      },
      "source": [
        "### Working with pdfs\n",
        "\n",
        "We need to convert a PDF to an array of images. One image per page.\n",
        "We use the `pdf2image` library for this task. Secondary, we also extract the text contents of the PDF using `pypdf`.\n",
        "\n",
        "NOTE: This step requires that you have `poppler` installed on your system. Read more in [pdf2image](https://pdf2image.readthedocs.io/en/latest/installation.html) docs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-1v-qZ32OgW"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from pdf2image import convert_from_path\n",
        "from pypdf import PdfReader\n",
        "\n",
        "\n",
        "def download_pdf(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return BytesIO(response.content)\n",
        "    else:\n",
        "        raise Exception(f\"Failed to download PDF: Status code {response.status_code}\")\n",
        "\n",
        "\n",
        "def get_pdf_images(pdf_url):\n",
        "    # Download the PDF\n",
        "    pdf_file = download_pdf(pdf_url)\n",
        "    # Save the PDF temporarily to disk (pdf2image requires a file path)\n",
        "    temp_file = \"temp.pdf\"\n",
        "    with open(temp_file, \"wb\") as f:\n",
        "        f.write(pdf_file.read())\n",
        "    reader = PdfReader(temp_file)\n",
        "    page_texts = []\n",
        "    for page_number in range(len(reader.pages)):\n",
        "        page = reader.pages[page_number]\n",
        "        text = page.extract_text()\n",
        "        page_texts.append(text)\n",
        "    images = convert_from_path(temp_file)\n",
        "    assert len(images) == len(page_texts)\n",
        "    return (images, page_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l41eBWppMr85"
      },
      "source": [
        "We define a few sample PDFs to work with. The PDFs are discovered from [this url](https://www.conocophillips.com/company-reports-resources/sustainability-reporting/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZIGixLBRyEi"
      },
      "outputs": [],
      "source": [
        "sample_pdfs = [\n",
        "    {\n",
        "        \"title\": \"ConocoPhillips Sustainability Highlights - Nature (24-0976)\",\n",
        "        \"url\": \"https://static.conocophillips.com/files/resources/24-0976-sustainability-highlights_nature.pdf\",\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"ConocoPhillips Managing Climate Related Risks\",\n",
        "        \"url\": \"https://static.conocophillips.com/files/resources/conocophillips-2023-managing-climate-related-risks.pdf\",\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"ConocoPhillips 2023 Sustainability Report\",\n",
        "        \"url\": \"https://static.conocophillips.com/files/resources/conocophillips-2023-sustainability-report.pdf\",\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvTZSRuDMr85"
      },
      "source": [
        "Now we can convert the PDFs to images and also extract the text content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaDInfmT3Tbu"
      },
      "outputs": [],
      "source": [
        "for pdf in sample_pdfs:\n",
        "    page_images, page_texts = get_pdf_images(pdf[\"url\"])\n",
        "\n",
        "    pdf[\"images\"] = page_images\n",
        "    pdf[\"texts\"] = page_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3vBUFwATIqk"
      },
      "source": [
        "Let us look at the extracted image of the first PDF page. This is the document side input to ColPali, one image per page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGAXQ-0E3jQS"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "display(scale_image(sample_pdfs[0][\"images\"][0], 720))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V8Ccje1Mr86"
      },
      "source": [
        "Let us also look at the extracted text content of the first PDF page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYO_Ts0cMr86"
      },
      "outputs": [],
      "source": [
        "print(sample_pdfs[0][\"texts\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmbgRjE3Mr86"
      },
      "source": [
        "Notice how the layout and order of the text is different from the image representation. Note that\n",
        "\n",
        "- The headlines NATURE and Sustainability have been combined into one word (NATURESustainability).\n",
        "- The 0.03% has been converted to 0.03 and order is not preserved in the text representation.\n",
        "- The data in the infographics is not represented in the text representation. For example the source water distribution in the infographics is not represented in the text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoRwcpJTMr86"
      },
      "source": [
        "Now we use the ColPali model to generate embeddings of the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRp3P9SlTK97"
      },
      "outputs": [],
      "source": [
        "for pdf in sample_pdfs:\n",
        "    page_embeddings = []\n",
        "    dataloader = DataLoader(\n",
        "        pdf[\"images\"],\n",
        "        batch_size=2,\n",
        "        shuffle=False,\n",
        "        collate_fn=lambda x: processor(images=x, return_tensors=\"pt\"),\n",
        "    )\n",
        "    for batch_doc in tqdm(dataloader):\n",
        "        with torch.no_grad():\n",
        "            batch_doc = {k: v.to(model.device) for k, v in batch_doc.items()}\n",
        "            embeddings_doc = model(**batch_doc).embeddings\n",
        "            page_embeddings.extend(list(torch.unbind(embeddings_doc.to(\"cpu\"))))\n",
        "    pdf[\"embeddings\"] = page_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDwcMbWwMr86"
      },
      "source": [
        "Now we are done with the document side embeddings, we now convert the embeddings to Vespa JSON format so we can store (and index) them in Vespa.\n",
        "Details in [Vespa JSON feed format doc](https://docs.vespa.ai/en/reference/document-json-format.html).\n",
        "\n",
        "\n",
        "We use binary quantization (BQ) of the page level ColPali vector embeddings to reduce their size by 32x.\n",
        "\n",
        "Read more about binarization of multi-vector representations in the [colbert blog post](https://blog.vespa.ai/announcing-colbert-embedder-in-vespa/).\n",
        "\n",
        "The binarization step maps 128 dimensional floats to 128 bits, or 16 bytes per vector. Reducing the size by 32x. On the [DocVQA benchmark](https://huggingface.co/datasets/vidore/docvqa_test_subsampled), binarization results in a small drop in ranking accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FObCnKQQeHQ_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "vespa_feed = []\n",
        "for pdf in sample_pdfs:\n",
        "    url = pdf[\"url\"]\n",
        "    title = pdf[\"title\"]\n",
        "    for page_number, (page_text, embedding, image) in enumerate(\n",
        "        zip(pdf[\"texts\"], pdf[\"embeddings\"], pdf[\"images\"])\n",
        "    ):\n",
        "        base_64_image = get_base64_image(scale_image(image, 640), add_url_prefix=False)\n",
        "        embedding_dict = dict()\n",
        "        for idx, patch_embedding in enumerate(embedding):\n",
        "            binary_vector = (\n",
        "                np.packbits(np.where(patch_embedding > 0, 1, 0))\n",
        "                .astype(np.int8)\n",
        "                .tobytes()\n",
        "                .hex()\n",
        "            )\n",
        "            embedding_dict[idx] = binary_vector\n",
        "        page = {\n",
        "            \"id\": hash(url + str(page_number)),\n",
        "            \"fields\": {\n",
        "                \"url\": url,\n",
        "                \"title\": title,\n",
        "                \"page_number\": page_number,\n",
        "                \"image\": base_64_image,\n",
        "                \"text\": page_text,\n",
        "                \"embedding\": embedding_dict,\n",
        "            },\n",
        "        }\n",
        "        vespa_feed.append(page)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yI8WZhURMr86"
      },
      "source": [
        "### Configure Vespa\n",
        "[PyVespa](https://vespa-engine.github.io/pyvespa/) helps us build the [Vespa application package](https://docs.vespa.ai/en/application-packages.html).\n",
        "A Vespa application package consists of configuration files, schemas, models, and code (plugins).\n",
        "\n",
        "First, we define a [Vespa schema](https://docs.vespa.ai/en/schemas.html) with the fields we want to store and their type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd75Cgr6Mr87"
      },
      "outputs": [],
      "source": [
        "from vespa.package import Schema, Document, Field, FieldSet, HNSW\n",
        "\n",
        "colpali_schema = Schema(\n",
        "    name=\"pdf_page\",\n",
        "    document=Document(\n",
        "        fields=[\n",
        "            Field(\n",
        "                name=\"id\", type=\"string\", indexing=[\"summary\", \"index\"], match=[\"word\"]\n",
        "            ),\n",
        "            Field(name=\"url\", type=\"string\", indexing=[\"summary\", \"index\"]),\n",
        "            Field(\n",
        "                name=\"title\",\n",
        "                type=\"string\",\n",
        "                indexing=[\"summary\", \"index\"],\n",
        "                match=[\"text\"],\n",
        "                index=\"enable-bm25\",\n",
        "            ),\n",
        "            Field(name=\"page_number\", type=\"int\", indexing=[\"summary\", \"attribute\"]),\n",
        "            Field(name=\"image\", type=\"raw\", indexing=[\"summary\"]),\n",
        "            Field(\n",
        "                name=\"text\",\n",
        "                type=\"string\",\n",
        "                indexing=[\"index\"],\n",
        "                match=[\"text\"],\n",
        "                index=\"enable-bm25\",\n",
        "            ),\n",
        "            Field(\n",
        "                name=\"embedding\",\n",
        "                type=\"tensor<int8>(patch{}, v[16])\",\n",
        "                indexing=[\n",
        "                    \"attribute\",\n",
        "                    \"index\",\n",
        "                ],  # adds HNSW index for candidate retrieval.\n",
        "                ann=HNSW(\n",
        "                    distance_metric=\"hamming\",\n",
        "                    max_links_per_node=32,\n",
        "                    neighbors_to_explore_at_insert=400,\n",
        "                ),\n",
        "            ),\n",
        "        ]\n",
        "    ),\n",
        "    fieldsets=[FieldSet(name=\"default\", fields=[\"title\", \"text\"])],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7umkIKMMr87"
      },
      "source": [
        "Notice the `embedding` field which is a tensor field with the type `tensor<int8>(patch{}, v[16])`.\n",
        "This is the field we use to represent the patch embeddings from ColPali.\n",
        "\n",
        "We also enable [HNSW indexing](https://docs.vespa.ai/en/approximate-nn-hnsw.html)\n",
        "for this field to enable fast nearest neighbor search which is used for candidate retrieval.\n",
        "\n",
        "We use [binary hamming distance](https://docs.vespa.ai/en/nearest-neighbor-search.html#using-binary-embeddings-with-hamming-distance)\n",
        "as an approximation of the cosine similarity. Hamming distance is a good approximation\n",
        "for binary representations, and it is much faster to compute than cosine similarity/dot product.\n",
        "\n",
        "The `embedding` field is an example of a mixed tensor where we combine one mapped (sparse) dimensions with a dense dimension.\n",
        "\n",
        "Read more in [Tensor guide](https://docs.vespa.ai/en/tensor-user-guide.html). We also enable [BM25](https://docs.vespa.ai/en/reference/bm25.html) for the `title` and `texts` fields. Notice that the `image` field use type `raw` to store the binary image data, encoded with as a base64 string.\n",
        "\n",
        "Create the Vespa [application package](https://docs.vespa.ai/en/application-packages):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpFN3FydMr87"
      },
      "outputs": [],
      "source": [
        "from vespa.package import ApplicationPackage\n",
        "\n",
        "vespa_app_name = \"visionrag5\"\n",
        "vespa_application_package = ApplicationPackage(\n",
        "    name=vespa_app_name, schema=[colpali_schema]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK_OOfeJMr87"
      },
      "source": [
        "Now we define how we want to rank the pages for a query. We use Vespa's support for [BM25](https://docs.vespa.ai/en/reference/bm25.html) for the text, and\n",
        "late interaction with Max Sim for the image embeddings.\n",
        "\n",
        "This means that we use the the text representations as a candidate retrieval phase,  then we use the ColPALI embeddings with MaxSim\n",
        "to rerank the pages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jjw3LR-KMr87"
      },
      "outputs": [],
      "source": [
        "from vespa.package import RankProfile, Function, FirstPhaseRanking, SecondPhaseRanking\n",
        "\n",
        "colpali_profile = RankProfile(\n",
        "    name=\"default\",\n",
        "    inputs=[(\"query(qt)\", \"tensor<float>(querytoken{}, v[128])\")],\n",
        "    functions=[\n",
        "        Function(\n",
        "            name=\"max_sim\",\n",
        "            expression=\"\"\"\n",
        "                sum(\n",
        "                    reduce(\n",
        "                        sum(\n",
        "                            query(qt) * unpack_bits(attribute(embedding)) , v\n",
        "                        ),\n",
        "                        max, patch\n",
        "                    ),\n",
        "                    querytoken\n",
        "                )\n",
        "            \"\"\",\n",
        "        ),\n",
        "        Function(name=\"bm25_score\", expression=\"bm25(title) + bm25(text)\"),\n",
        "    ],\n",
        "    first_phase=FirstPhaseRanking(expression=\"bm25_score\"),\n",
        "    second_phase=SecondPhaseRanking(expression=\"max_sim\", rerank_count=100),\n",
        ")\n",
        "colpali_schema.add_rank_profile(colpali_profile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOBwk6hLMr87"
      },
      "source": [
        "The first phase uses a linear combination of BM25 scores for the text fields, and the second phase uses the MaxSim function with the image embeddings. Notice that Vespa supports a `unpack_bits` function to convert the 16 compressed binary vectors to 128-dimensional floats for the MaxSim function. The query input tensor is not compressed and using full float resolution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icD4jk0SMr87"
      },
      "source": [
        "### Deploy the application to Vespa Cloud\n",
        "\n",
        "With the configured application, we can deploy it to [Vespa Cloud](https://cloud.vespa.ai/en/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c89Ln5ypMr87"
      },
      "source": [
        "To deploy the application to Vespa Cloud we need to create a tenant in the Vespa Cloud:\n",
        "\n",
        "Create a tenant at [console.vespa-cloud.com](https://console.vespa-cloud.com/) (unless you already have one).\n",
        "This step requires a Google or GitHub account, and will start your [free trial](https://cloud.vespa.ai/en/free-trial).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ixJ80mgMr87"
      },
      "outputs": [],
      "source": [
        "from vespa.deployment import VespaCloud\n",
        "import os\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# Replace with your tenant name from the Vespa Cloud Console\n",
        "tenant_name = \"vespa-team\"\n",
        "\n",
        "key = os.getenv(\"VESPA_TEAM_API_KEY\", None)\n",
        "if key is not None:\n",
        "    key = key.replace(r\"\\n\", \"\\n\")  # To parse key correctly\n",
        "\n",
        "vespa_cloud = VespaCloud(\n",
        "    tenant=tenant_name,\n",
        "    application=vespa_app_name,\n",
        "    key_content=key,  # Key is only used for CI/CD testing of this notebook. Can be removed if logging in interactively\n",
        "    application_package=vespa_application_package,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JObAVw-HMr88"
      },
      "source": [
        "Now deploy the app to Vespa Cloud dev zone.\n",
        "\n",
        "The first deployment typically takes 2 minutes until the endpoint is up.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KREiKN-xMr88"
      },
      "outputs": [],
      "source": [
        "from vespa.application import Vespa\n",
        "\n",
        "app: Vespa = vespa_cloud.deploy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEj5xU1qMr88"
      },
      "outputs": [],
      "source": [
        "print(\"Number of PDF pages:\", len(vespa_feed))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dZkCsSWMr88"
      },
      "source": [
        "Index the documents in Vespa using the Vespa HTTP API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJeqi_8PMr8_"
      },
      "outputs": [],
      "source": [
        "from vespa.io import VespaResponse\n",
        "\n",
        "\n",
        "def callback(response: VespaResponse, id: str):\n",
        "    if not response.is_successful():\n",
        "        print(\n",
        "            f\"Failed to feed document {id} with status code {response.status_code}: Reason {response.get_json()}\"\n",
        "        )\n",
        "\n",
        "\n",
        "# Feed data into Vespa synchronously\n",
        "app.feed_iterable(vespa_feed, schema=\"pdf_page\", callback=callback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2pUyGjYf4Wv"
      },
      "source": [
        "### Querying Vespa\n",
        "\n",
        "Ok, so now we have indexed the PDF pages in Vespa. Let us now obtain ColPali embeddings for a few text queries and\n",
        "use it during ranking of the indexed pdf pages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPvdNc3kMr8_"
      },
      "source": [
        "Now we can query Vespa with the text query and rerank the results using the ColPali embeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2U58J_B5-L6"
      },
      "outputs": [],
      "source": [
        "queries = [\n",
        "    \"Percentage of non-fresh water as source?\",\n",
        "    \"Policies related to nature risk?\",\n",
        "    \"How much of produced water is recycled?\",\n",
        "]\n",
        "dataloader = DataLoader(\n",
        "    queries,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=lambda x: processor(text=x, return_tensors=\"pt\"),\n",
        ")\n",
        "qs = []\n",
        "for batch_query in dataloader:\n",
        "    with torch.no_grad():\n",
        "        batch_query = {k: v.to(model.device) for k, v in batch_query.items()}\n",
        "        embeddings_query = model(**batch_query).embeddings\n",
        "        qs.extend(list(torch.unbind(embeddings_query.to(\"cpu\"))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwujKAebMr8_"
      },
      "source": [
        "Obtain the query embeddings using the ColPali model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxeDd3mcYDpL"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(\n",
        "    queries,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=lambda x: processor(text=x, return_tensors=\"pt\"),\n",
        ")\n",
        "qs = []\n",
        "for batch_query in dataloader:\n",
        "    with torch.no_grad():\n",
        "        batch_query = {k: v.to(model.device) for k, v in batch_query.items()}\n",
        "        embeddings_query = model(**batch_query).embeddings\n",
        "        qs.extend(list(torch.unbind(embeddings_query.to(\"cpu\"))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI83UfYlMr8_"
      },
      "source": [
        "We create a simple routine to display the results. We render the image and the title of the retrieved page/document.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tyhfm71Mr8_"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "def display_query_results(query, response, hits=5):\n",
        "    query_time = response.json.get(\"timing\", {}).get(\"searchtime\", -1)\n",
        "    query_time = round(query_time, 2)\n",
        "    count = response.json.get(\"root\", {}).get(\"fields\", {}).get(\"totalCount\", 0)\n",
        "    html_content = f\"<h3>Query text: '{query}', query time {query_time}s, count={count}, top results:</h3>\"\n",
        "\n",
        "    for i, hit in enumerate(response.hits[:hits]):\n",
        "        title = hit[\"fields\"][\"title\"]\n",
        "        url = hit[\"fields\"][\"url\"]\n",
        "        page = hit[\"fields\"][\"page_number\"]\n",
        "        image = hit[\"fields\"][\"image\"]\n",
        "        score = hit[\"relevance\"]\n",
        "\n",
        "        html_content += f\"<h4>PDF Result {i + 1}</h4>\"\n",
        "        html_content += f'<p><strong>Title:</strong> <a href=\"{url}\">{title}</a>, page {page+1} with score {score:.2f}</p>'\n",
        "        html_content += (\n",
        "            f'<img src=\"data:image/png;base64,{image}\" style=\"max-width:100%;\">'\n",
        "        )\n",
        "\n",
        "    display(HTML(html_content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2fvQmfBMr8_"
      },
      "source": [
        "Query Vespa with the queries and display the results, here we are using the `default` rank profile.\n",
        "\n",
        "Note that we retrieve using textual representation with `userInput(@userQuery)`, this means that we use the BM25 ranking for the extracted text in the first ranking phase and then re-rank the top-k pages using the ColPali embeddings.\n",
        "\n",
        "Later in this notebook we will use Vespa's support for approximate nearest neighbor search (`nearestNeighbor`) to retrieve directly using the ColPali embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVb2ENZKMr8_"
      },
      "outputs": [],
      "source": [
        "from vespa.io import VespaQueryResponse\n",
        "\n",
        "async with app.asyncio(connections=1, timeout=120) as session:\n",
        "    for idx, query in enumerate(queries):\n",
        "        query_embedding = {k: v.tolist() for k, v in enumerate(qs[idx])}\n",
        "        response: VespaQueryResponse = await session.query(\n",
        "            yql=\"select title,url,image,page_number from pdf_page where userInput(@userQuery)\",\n",
        "            ranking=\"default\",\n",
        "            userQuery=query,\n",
        "            timeout=120,\n",
        "            hits=3,\n",
        "            body={\"input.query(qt)\": query_embedding, \"presentation.timing\": True},\n",
        "        )\n",
        "        assert response.is_successful()\n",
        "        display_query_results(query, response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXwD8ZVrMr8_"
      },
      "source": [
        "### Using nearestNeighbor for retrieval\n",
        "\n",
        "In the above example, we used the ColPali embeddings in ranking, but using the text query for retrieval.\n",
        "This is a reasonable approach for text-heavy documents where the text representation is the most important and where ColPali embeddings are used to\n",
        "re-rank the top-k documents from the text retrieval phase.\n",
        "\n",
        "In some cases, the ColPali embeddings are the most important and we want\n",
        "to demonstrate how we can use HNSW indexing with binary hamming distance to retrieve the most similar pages to a query and\n",
        "then have two steps of re-ranking using the ColPali embeddings.\n",
        "\n",
        "All the phases here are executed locally inside the Vespa content node(s) so that no vector data needs\n",
        "to cross the network.\n",
        "\n",
        "Let us add a new rank-profile to the schema, the `nearestNeighbor` operator takes a query tensor and a field tensor as argument and\n",
        "we need to define the query tensors types in the rank-profile."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ti0x59_KMr8_"
      },
      "outputs": [],
      "source": [
        "from vespa.package import RankProfile, Function, FirstPhaseRanking, SecondPhaseRanking\n",
        "\n",
        "input_query_tensors = []\n",
        "MAX_QUERY_TERMS = 64\n",
        "for i in range(MAX_QUERY_TERMS):\n",
        "    input_query_tensors.append((f\"query(rq{i})\", \"tensor<int8>(v[16])\"))\n",
        "\n",
        "input_query_tensors.append((\"query(qt)\", \"tensor<float>(querytoken{}, v[128])\"))\n",
        "input_query_tensors.append((\"query(qtb)\", \"tensor<int8>(querytoken{}, v[16])\"))\n",
        "\n",
        "colpali_retrieval_profile = RankProfile(\n",
        "    name=\"retrieval-and-rerank\",\n",
        "    inputs=input_query_tensors,\n",
        "    functions=[\n",
        "        Function(\n",
        "            name=\"max_sim\",\n",
        "            expression=\"\"\"\n",
        "                sum(\n",
        "                    reduce(\n",
        "                        sum(\n",
        "                            query(qt) * unpack_bits(attribute(embedding)) , v\n",
        "                        ),\n",
        "                        max, patch\n",
        "                    ),\n",
        "                    querytoken\n",
        "                )\n",
        "            \"\"\",\n",
        "        ),\n",
        "        Function(\n",
        "            name=\"max_sim_binary\",\n",
        "            expression=\"\"\"\n",
        "                sum(\n",
        "                  reduce(\n",
        "                    1/(1 + sum(\n",
        "                        hamming(query(qtb), attribute(embedding)) ,v)\n",
        "                    ),\n",
        "                    max,\n",
        "                    patch\n",
        "                  ),\n",
        "                  querytoken\n",
        "                )\n",
        "            \"\"\",\n",
        "        ),\n",
        "    ],\n",
        "    first_phase=FirstPhaseRanking(expression=\"max_sim_binary\"),\n",
        "    second_phase=SecondPhaseRanking(expression=\"max_sim\", rerank_count=10),\n",
        ")\n",
        "colpali_schema.add_rank_profile(colpali_retrieval_profile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI7iBQ39Mr8_"
      },
      "source": [
        "We define two functions, one for the first phase and one for the second phase. Instead of the float representations, we use the binary representations with inverted hamming distance in the first phase. Now, we need to re-deploy the application to Vespa Cloud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JL_V-pdMr8_"
      },
      "outputs": [],
      "source": [
        "from vespa.application import Vespa\n",
        "\n",
        "app: Vespa = vespa_cloud.deploy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pev8-G6IMr9A"
      },
      "source": [
        "Now we can query Vespa with the text queries and use the `nearestNeighbor` operator to retrieve the most similar pages to the query and pass the different query tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GD5q0i0zMr9A"
      },
      "outputs": [],
      "source": [
        "from vespa.io import VespaQueryResponse\n",
        "\n",
        "target_hits_per_query_tensor = (\n",
        "    20  # this is a hyper parameter that can be tuned for speed versus accuracy\n",
        ")\n",
        "async with app.asyncio(connections=1, timeout=180) as session:\n",
        "    for idx, query in enumerate(queries):\n",
        "        float_query_embedding = {k: v.tolist() for k, v in enumerate(qs[idx])}\n",
        "        binary_query_embeddings = dict()\n",
        "        for k, v in float_query_embedding.items():\n",
        "            binary_query_embeddings[k] = (\n",
        "                np.packbits(np.where(np.array(v) > 0, 1, 0)).astype(np.int8).tolist()\n",
        "            )\n",
        "\n",
        "        # The mixed tensors used in MaxSim calculations\n",
        "        # We use both binary and float representations\n",
        "        query_tensors = {\n",
        "            \"input.query(qtb)\": binary_query_embeddings,\n",
        "            \"input.query(qt)\": float_query_embedding,\n",
        "        }\n",
        "        # The query tensors used in the nearest neighbor calculations\n",
        "        for i in range(0, len(binary_query_embeddings)):\n",
        "            query_tensors[f\"input.query(rq{i})\"] = binary_query_embeddings[i]\n",
        "        nn = []\n",
        "        for i in range(0, len(binary_query_embeddings)):\n",
        "            nn.append(\n",
        "                f\"({{targetHits:{target_hits_per_query_tensor}}}nearestNeighbor(embedding,rq{i}))\"\n",
        "            )\n",
        "        # We use a OR operator to combine the nearest neighbor operator\n",
        "        nn = \" OR \".join(nn)\n",
        "        response: VespaQueryResponse = await session.query(\n",
        "            yql=f\"select title, url, image, page_number from pdf_page where {nn}\",\n",
        "            ranking=\"retrieval-and-rerank\",\n",
        "            timeout=120,\n",
        "            hits=3,\n",
        "            body={**query_tensors, \"presentation.timing\": True},\n",
        "        )\n",
        "        assert response.is_successful()\n",
        "        display_query_results(query, response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrL-77ROMr9A"
      },
      "source": [
        "Depending on the scale, we can evaluate changing different number of targetHits per nearestNeighbor operator and the ranking depths in the two phases. We can also parallelize the ranking phases by using more threads per query request to reduce latency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE_IgitmMr9A"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we have demonstrated how to represent ColPali in Vespa. We have generated embeddings for images of PDF pages using ColPali and stored the embeddings in Vespa using [mixed tensors](https://docs.vespa.ai/en/tensor-user-guide.html).\n",
        "\n",
        "We demonstrated how to store the base64 encoded image using the `raw` Vespa field type, plus meta data like title and url.\n",
        "We have demonstrated how to retrieve relevant pages for a query using the embeddings generated by ColPali.\n",
        "\n",
        "This notebook can be extended to include more complex ranking models, more complex queries, and more complex data structures, including metadata and other fields which can be filtered on or used for ranking."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KZOGXcXMr9A"
      },
      "source": [
        "## Cleanup\n",
        "\n",
        "When this notebook is running in CI, we want to delete the application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68NHoR_SMr9A"
      },
      "outputs": [],
      "source": [
        "if os.getenv(\"CI\", \"false\") == \"true\":\n",
        "    vespa_cloud.delete()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b5672a16be04e3981882b338ee52618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d67bb152de9c40be99fbf9036415a007",
              "IPY_MODEL_2545fd7c8e75489cb84a8e55d04b0a9e",
              "IPY_MODEL_3bd710c8728146df8d2108f9906e6e66"
            ],
            "layout": "IPY_MODEL_aa6badb696b345fe9241052af409647c"
          }
        },
        "d67bb152de9c40be99fbf9036415a007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_964bea24e4a947699e98b4e347305694",
            "placeholder": "​",
            "style": "IPY_MODEL_7e625e90e4ac495d895202744bf36e2f",
            "value": "config.json: "
          }
        },
        "2545fd7c8e75489cb84a8e55d04b0a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3de350f3eb3b49fca11f14d11fa8416e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_986d2d53b95f4490b04db050d17763c2",
            "value": 1
          }
        },
        "3bd710c8728146df8d2108f9906e6e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02956fb81b0a489e9e1d0cf00af2c739",
            "placeholder": "​",
            "style": "IPY_MODEL_4ee99609ec534a059bcff4f788166849",
            "value": " 1.05k/? [00:00&lt;00:00, 29.4kB/s]"
          }
        },
        "aa6badb696b345fe9241052af409647c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "964bea24e4a947699e98b4e347305694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e625e90e4ac495d895202744bf36e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3de350f3eb3b49fca11f14d11fa8416e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "986d2d53b95f4490b04db050d17763c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02956fb81b0a489e9e1d0cf00af2c739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ee99609ec534a059bcff4f788166849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1490c3af015448088277755693125d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2b7592676fe4b07a7d3a8cd294e7f75",
              "IPY_MODEL_a220fdcb2cf14cde8ea6ae6baf154267",
              "IPY_MODEL_c52189f0f186493da9036acedd9cf8b7"
            ],
            "layout": "IPY_MODEL_2b64057c89144bbabb001fba75402bf3"
          }
        },
        "a2b7592676fe4b07a7d3a8cd294e7f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_604a2759912a42f3921569626cf04d60",
            "placeholder": "​",
            "style": "IPY_MODEL_a2369645d7544597b5e481beb007adf0",
            "value": "model.safetensors.index.json: "
          }
        },
        "a220fdcb2cf14cde8ea6ae6baf154267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4301536cda4541808a8dfa7d50340b10",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1edb8d32148467dbd4d2b971b35d602",
            "value": 1
          }
        },
        "c52189f0f186493da9036acedd9cf8b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c276cb31cc24e19ae864bd3284369cb",
            "placeholder": "​",
            "style": "IPY_MODEL_5690c1579912452fb0106ac3038862ce",
            "value": " 65.1k/? [00:00&lt;00:00, 2.15MB/s]"
          }
        },
        "2b64057c89144bbabb001fba75402bf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "604a2759912a42f3921569626cf04d60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2369645d7544597b5e481beb007adf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4301536cda4541808a8dfa7d50340b10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c1edb8d32148467dbd4d2b971b35d602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c276cb31cc24e19ae864bd3284369cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5690c1579912452fb0106ac3038862ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cbb6e9203a14db5b82f3967370aec64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78621a41f4b341c39cf1dcadfc7284fd",
              "IPY_MODEL_5d8e9a315d2643c6b69d4f4c99372276",
              "IPY_MODEL_8b271605a2f94b8daa100d9e41baa6b9"
            ],
            "layout": "IPY_MODEL_bae55b3298f44a4fb9978a7983dce764"
          }
        },
        "78621a41f4b341c39cf1dcadfc7284fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_482f308812374853a3f73e8343359101",
            "placeholder": "​",
            "style": "IPY_MODEL_e52a23a75dfd4c4e8ec257dfbd6404af",
            "value": "Fetching 2 files:   0%"
          }
        },
        "5d8e9a315d2643c6b69d4f4c99372276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e50ce4a951949efbd49636fc26941bc",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bddb2de8291f43b9a0bfb47f9d0eacad",
            "value": 0
          }
        },
        "8b271605a2f94b8daa100d9e41baa6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1102a3de22d4403a65681138165a151",
            "placeholder": "​",
            "style": "IPY_MODEL_032cbae8047649f7bd22daad505a0c17",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "bae55b3298f44a4fb9978a7983dce764": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "482f308812374853a3f73e8343359101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e52a23a75dfd4c4e8ec257dfbd6404af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e50ce4a951949efbd49636fc26941bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bddb2de8291f43b9a0bfb47f9d0eacad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1102a3de22d4403a65681138165a151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "032cbae8047649f7bd22daad505a0c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "374fd86b4b1a4a87a61e896964ddf8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecd30cda8f3c45bd91829b5fee468b6e",
              "IPY_MODEL_40fdf79571ac4b638d252c9d9f24b59b",
              "IPY_MODEL_8b1c0fdbd3a742b5b4dd213b348ba6cb"
            ],
            "layout": "IPY_MODEL_0e1f204dd80840d981c59b1ae5cd2b0c"
          }
        },
        "ecd30cda8f3c45bd91829b5fee468b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baf29665b4f04822aad9b69ede4d307b",
            "placeholder": "​",
            "style": "IPY_MODEL_34dee48cdaa246c1a44453d43634c657",
            "value": "model-00001-of-00002.safetensors:  80%"
          }
        },
        "40fdf79571ac4b638d252c9d9f24b59b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19dd3dcae1244ca8b461027b31a78add",
            "max": 4986816144,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9609ec9a25c49d2b74ecc4d75e0ea07",
            "value": 3980998495
          }
        },
        "8b1c0fdbd3a742b5b4dd213b348ba6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d887f859e942484b906ba9162b831ef8",
            "placeholder": "​",
            "style": "IPY_MODEL_d1d5d2ffa6844956a868867023dfc3f3",
            "value": " 3.98G/4.99G [02:58&lt;00:33, 30.2MB/s]"
          }
        },
        "0e1f204dd80840d981c59b1ae5cd2b0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf29665b4f04822aad9b69ede4d307b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34dee48cdaa246c1a44453d43634c657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19dd3dcae1244ca8b461027b31a78add": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9609ec9a25c49d2b74ecc4d75e0ea07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d887f859e942484b906ba9162b831ef8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1d5d2ffa6844956a868867023dfc3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c95c26d58e984123b493a91a78530493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96ef6b50c5d443a69472508fe2a8fec8",
              "IPY_MODEL_3964bcff08f7480ab94bb4e232fbff03",
              "IPY_MODEL_595692f07b2541ce869f15b53efedfb5"
            ],
            "layout": "IPY_MODEL_2f4be02421f74a64a805b34319550ca1"
          }
        },
        "96ef6b50c5d443a69472508fe2a8fec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3181b6eae242418d8ad240fe71dae9f8",
            "placeholder": "​",
            "style": "IPY_MODEL_29639bfd4b6648df9d20dc33430d0d08",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "3964bcff08f7480ab94bb4e232fbff03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c262e8d2c5474b9a87cbb58113432fe9",
            "max": 862495464,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f72f7c7bd7614c79a09ed3e0740098a2",
            "value": 862495464
          }
        },
        "595692f07b2541ce869f15b53efedfb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6801b8d612ac492f9f5588bc6e7461cf",
            "placeholder": "​",
            "style": "IPY_MODEL_849e9a2837bd42a18289d6c5abf483d4",
            "value": " 862M/862M [01:26&lt;00:00, 4.71MB/s]"
          }
        },
        "2f4be02421f74a64a805b34319550ca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3181b6eae242418d8ad240fe71dae9f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29639bfd4b6648df9d20dc33430d0d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c262e8d2c5474b9a87cbb58113432fe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f72f7c7bd7614c79a09ed3e0740098a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6801b8d612ac492f9f5588bc6e7461cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "849e9a2837bd42a18289d6c5abf483d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}